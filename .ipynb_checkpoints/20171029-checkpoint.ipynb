{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "The objective of this assignment is to get you familiarizewith  the  problems  of  `classification`  and  `verification`with a popular problem space of `face`\n",
    "\n",
    "This jupyter notebook is meant to be used in conjunction with the full questions in the assignment pdf.\n",
    "\n",
    "## Instructions\n",
    "- Write your code and analyses in the indicated cells.\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not attempt to change the contents of the other cells.\n",
    "\n",
    "## Allowed Libraries\n",
    "- All libraries are allowed \n",
    "\n",
    "## Datasets \n",
    "- 3 datasets are provided. Load the data from the drive [link](!https://drive.google.com/file/d/1ujsKv9W5eidb4TXt1pnsqwDKVDFtzZTh/view?usp=sharing).\n",
    "- Unzip the downloaded file and store the files in a folder called `datasets`. Keep the `datasets` folder in the same directory as of the jupyter notebook \n",
    "\n",
    "## Submission\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Rename the notebook to `<roll_number>.ipynb` and submit ONLY the notebook file on moodle.\n",
    "- Upload  the  notebook,  report  and  classification  results as a zip file to moodle. Name the zip file as `<rollnumber>_assignment2.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (0.21.2)\n",
      "Requirement already satisfied: matplotlib in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (3.1.0)\n",
      "Requirement already satisfied: Pillow in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (6.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.16.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/aizensosuke/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Installing Libraries\n",
    "!pip install scikit-learn matplotlib Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "import random\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "# Loading and plotting data\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Features\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import _class_means,_class_cov\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "- Image size: Bigger images create better representation but would require more computation. Choose the correct image size based on your Laptop configuration. \n",
    "- is_grayscale: Should you take grayscale images? Or rgb images? Choose whichever gives better representation for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    'image_size': 32,\n",
    "    'is_grayscale': False,\n",
    "    'val_split': 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "cfw_dict = {'Amitabhbachan': 0,\n",
    "    'AamirKhan': 1,\n",
    "    'DwayneJohnson': 2,\n",
    "    'AishwaryaRai': 3,\n",
    "    'BarackObama': 4,\n",
    "    'NarendraModi': 5,\n",
    "    'ManmohanSingh': 6,\n",
    "    'VladimirPutin': 7}\n",
    "\n",
    "imfdb_dict = {'MadhuriDixit': 0,\n",
    "     'Kajol': 1,\n",
    "     'SharukhKhan': 2,\n",
    "     'ShilpaShetty': 3,\n",
    "     'AmitabhBachan': 4,\n",
    "     'KatrinaKaif': 5,\n",
    "     'AkshayKumar': 6,\n",
    "     'Amir': 7}\n",
    "\n",
    "# Load Image using PIL for dataset\n",
    "def load_image(path):\n",
    "    im = Image.open(path).convert('L' if opt['is_grayscale'] else 'RGB')\n",
    "    im = im.resize((opt['image_size'],opt['image_size']))\n",
    "    im = np.array(im)\n",
    "    im = im/256\n",
    "    return im\n",
    "\n",
    "# Load the full data from directory\n",
    "def load_data(dir_path):\n",
    "    image_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    if \"CFW\" in dir_path:\n",
    "        label_dict = cfw_dict\n",
    "\n",
    "    elif \"yale\" in dir_path.lower():\n",
    "        label_dict = {}\n",
    "        for i in range(15):\n",
    "            label_dict[str(i+1)] = i\n",
    "    elif \"IMFDB\" in dir_path:\n",
    "        label_dict = imfdb_dict\n",
    "    else:\n",
    "        raise KeyError(\"Dataset not found.\")\n",
    "    \n",
    "    \n",
    "    for filename in sorted(os.listdir(dir_path)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            im = load_image(os.path.join(dir_path,filename))\n",
    "            y = filename.split('_')[0]\n",
    "            y = label_dict[y] \n",
    "            image_list.append(im)\n",
    "            y_list.append(y)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    y_list = np.array(y_list)\n",
    "\n",
    "    print(\"Dataset shape:\",image_list.shape)\n",
    "\n",
    "    return image_list,y_list\n",
    "\n",
    "# Display N Images in a nice format\n",
    "def disply_images(imgs,classes,row=1,col=2,w=64,h=64):\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    for i in range(1, col*row +1):\n",
    "        img = imgs[i-1]\n",
    "        fig.add_subplot(row, col, i)\n",
    "        \n",
    "        if opt['is_grayscale']:\n",
    "            plt.imshow(img , cmap='gray') \n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        \n",
    "        plt.title(\"Class:{}\".format(classes[i-1]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/IMFDB/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3c242506d87c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# eg.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./dataset/IMFDB/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_grayscale'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b49ac13643fc>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dir_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/IMFDB/'"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# eg.\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "method = ['PCA', 'KPCA', 'LDA', 'KLDA', 'VGG', 'RESNET', 'RESNET+VGG', 'KPCA+KLDA',  'ALL FEATURES']\n",
    "datasets = os.listdir('./dataset/')\n",
    "print(datasets)\n",
    "indices = ['0', '1', '2', '3', '4', '5', '6', '7', '8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Show sample images\n",
    "ind = np.random.randint(0,y.shape[0],6)\n",
    "disply_images(X[ind,...],y[ind], row=2,col=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "    You are provided 6 Features. These features are:\n",
    "   - Eigen Faces / PCA \n",
    "   - Kernel PCA\n",
    "   - Fisher Face / LDA\n",
    "   - Kernel Fisher Face\n",
    "   - VGG Features \n",
    "   - Resnet Features\n",
    "\n",
    "**VGG and Resnet features are last layer features learned by training a model for image classification**\n",
    "    \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Flatten to apply PCA/LDA\n",
    "X = X.reshape((N,H*W*C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dirpath):\n",
    "    X,y = load_data(dirpath)\n",
    "    N,H,W = X.shape[0:3]\n",
    "    C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "    X = X.reshape((N,H*W*C))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Eigen Face:\n",
    "Use principal component analysis to get the eigen faces. \n",
    "Go through the [documentation](!http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) on how to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(X,k):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=k)\n",
    "    X_k = pca.fit_transform(X)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Kernel Face:\n",
    "Use Kernel principal component analysis to get the eigen faces. \n",
    "\n",
    "There are different kernels that can be used. Eg. Poly, rbf, sigmoid. Choose the whichever gives the best result or representation. See [link](!https://data-flair.training/blogs/svm-kernel-functions/) for better understanding of these kernels  \n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_pca(X, k,kernel='rbf', degree=3):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use (“linear” | “poly” | “rbf” | “sigmoid” | “cosine” )\n",
    "        @param: d => Degree for poly kernels. Ignored by other kernels\n",
    "    \"\"\"\n",
    "    kpca = KernelPCA(n_components=k,kernel=kernel,degree=degree)\n",
    "    X_k = kpca.fit_transform(X)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fisher Face\n",
    "Another method similar to the eigenface technique is `fisherfaces` which uses linear discriminant analysis.\n",
    "This method for facial recognition is less sensitive to variation in lighting and pose of the face than using eigenfaces. Fisherface uses labelled data to retain more of the class-specific information during the dimension reduction stage.\n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda(X,y, k):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "    \"\"\"\n",
    "    lda = LDA(n_components=k)\n",
    "    X_k = lda.fit_transform(X,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Kernel Fisher Face\n",
    "Use LDA using different kernels similiar to KernelPCA. Here the input is directly transformed instead of using the kernel trick.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_lda(X,y,k,kernel='rbf',degree=3):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use ( “poly” | “rbf” | “sigmoid”)\n",
    "    \"\"\"\n",
    "    # Transform  input\n",
    "    if kernel == \"poly\":\n",
    "        X_transformed = X**degree\n",
    "    elif kernel == \"rbf\":\n",
    "        var = np.var(X)\n",
    "        X_transformed= np.exp(-X/(2*var))\n",
    "    elif kernel == \"sigmoid\":\n",
    "        X_transformed = np.tanh(X)\n",
    "    else: \n",
    "        raise NotImplementedError(\"Kernel {} Not defined\".format(kernel))\n",
    "        \n",
    "    klda = LDA(n_components=k)\n",
    "    X_k = klda.fit_transform(X,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. VGG Features\n",
    "VGG Neural Networks a 19 layer CNN architecture introduced by Andrew Zisserman([Link](!https://arxiv.org/pdf/1409.1556.pdf) to paper). We are providing you with the last fully connected layer of this model.\n",
    "\n",
    "The model was trained for face classification on each dataset and each feature the dimension of 4096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"VGG19_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Resnet Features\n",
    "\n",
    "[Residual neural networks](!https://arxiv.org/pdf/1512.03385.pdf) are CNN with large depth, to effectively train these netwrorks they utilize skip connections, or short-cuts to jump over some layers. This helps solving [vanishing gradient problem](!https://en.wikipedia.org/wiki/Vanishing_gradient_problem) \n",
    "\n",
    "A 50 layer resnet model was trained for face classification on each dataset. Each feature the dimension of 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"resnet50_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noeigenvals(X):\n",
    "    cov_mat = np.cov(X.T)\n",
    "    eigenval, eigenvec = np.linalg.eig(cov_mat)\n",
    "    eigenval = np.sort(eigenval)\n",
    "    eigenval = eigenval[::-1]\n",
    "    indices = np.where(eigenval.real>1e-1)\n",
    "    eigenval = eigenval[indices]\n",
    "    no_eigenvals = eigenval.shape[0]\n",
    "    return no_eigenvals, eigenval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_eigenvals = []\n",
    "eigenval = []\n",
    "counter = 0\n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    val = noeigenvals(X_input)\n",
    "    no_eigenvals.append(val[0])\n",
    "    eigenval.append(val[1])\n",
    "    counter = counter + 1\n",
    "# print(eigenval[0].shape)\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1(a). What are eigen faces? \n",
    "\n",
    "___________________________\n",
    "\n",
    "Your answers here (double click to edit)\n",
    "Eigenfaces is the name given to a set of top k eigenvectors when they are used in the computer vision problem of human face recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(b).  How many eigen vec-tors/faces are required to “satisfactorily” reconstruct a  person  in  these  three  datasets? (Don’t  forget  to make your argument based on eigen value spectrum) Show appropriate graphs, qualitative examples and make a convincing argument.\n",
    "\n",
    "Ans) Number of eigenvectors required depends on what percentage of original data gets represented in the reduced dimension space. If we set a threshold, say we want to capture greater than 90 percent of data for each dataset, then we can make an approximate guess for the number of components required by looking at the plot for cumulative explained variance vs no of components. Eigenspectrum plotted in the below code cells. Cumulative variance vs no of components also plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute your features \n",
    "# eg.\n",
    "#X_3D = get_kernel_lda(X,y,3)\n",
    "# X, y = load_dataset('./dataset/IMFDB/')\n",
    "def return_features(X, y, dirpath, no_eigenvals):\n",
    "#     print(X.shape)\n",
    "    X_PCA = get_pca(X, no_eigenvals)\n",
    "    X_KPCA = get_kernel_pca(X, no_eigenvals, 'rbf')\n",
    "    X_LDA = get_lda(X, y, 10)\n",
    "    X_KLDA = get_kernel_lda(X, y, 10)\n",
    "    X_VGG = get_vgg_features(dirpath)\n",
    "    X_RESNET = get_resnet_features(dirpath)\n",
    "    X_RESNET_VGG = np.concatenate((X_RESNET, X_VGG), axis=1)\n",
    "    X_KPCA_KLDA = np.concatenate((X_KPCA, X_KLDA), axis=1)\n",
    "    all_tuple = (X_PCA, X_KPCA, X_LDA, X_KLDA, X_VGG, X_RESNET)\n",
    "    X_ALL = np.concatenate(all_tuple, axis=1)\n",
    "    features = {\n",
    "        '0': X_PCA,\n",
    "        '1': X_KPCA,\n",
    "        '2': X_LDA,\n",
    "        '3': X_KLDA,\n",
    "        '4': X_VGG,\n",
    "        '5': X_RESNET,\n",
    "        '6': X_RESNET_VGG,\n",
    "        '7': X_KPCA_KLDA,\n",
    "        '8': X_ALL\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "features = return_features(X, y, dirpath, 100)\n",
    "#counter = 0\n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    for index in feature_input.keys():\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        no_class = len(np.unique(y_input))\n",
    "        palette = np.array(sns.color_palette(\"hls\", no_class))\n",
    "        ax.scatter(feature_input[index][:,0],feature_input[index][:,1],feature_input[index][:,2],c=palette[y_input.astype(np.int)])\n",
    "        ax.set_title(method[int(index)]+' '+data)\n",
    "        fig.savefig('a2plots/'+data+'/'+method[int(index)]+'.png')\n",
    "        #plt.close(fig)\n",
    "\n",
    "    #counter = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the eigen value spectrum\n",
    "counter = 0\n",
    "for data in datasets:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(data+' eigenspectrum')\n",
    "    plt.bar(np.arange(no_eigenvals[counter]), eigenval[counter].real)\n",
    "    plt.savefig('a2plots/'+data+'/eigenspectrum.png')\n",
    "    #plt.close()\n",
    "    counter = counter + 1\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_pca(*args):\n",
    "    #X_orig = args[0].reshape((N, H, W, C))\n",
    "    pca = PCA(n_components=args[1])\n",
    "    X_fit = pca.fit_transform(args[0])\n",
    "    X_reconstructed = pca.inverse_transform(X_fit)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.savefig('a2plots/'+args[2]+'/cum_variance.png')\n",
    "    plt.close()\n",
    "    return X_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_kpca(*args):\n",
    "    kpca = KernelPCA(n_components=args[1],kernel=args[2], gamma=2, degree=args[3] , fit_inverse_transform=True)\n",
    "    X_k = kpca.fit_transform(args[0])\n",
    "    X_reconstructed = kpca.inverse_transform(X_k)\n",
    "    return X_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(c). Reconstruct  the  image  back for each case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_images(choice, *args):\n",
    "    \"\"\"\n",
    "        Reconstruct the images back by just using the selected principal components. \n",
    "\n",
    "\n",
    "        You have to write the code in this code block.\n",
    "        You can change the functions provided above (eg, get_pca, get_lda) for your use case. \n",
    "            \n",
    "        @params: \n",
    "                Input parameters\n",
    "\n",
    "        @return reconstructed_X => reconstructed image\n",
    "        \n",
    "    \"\"\"\n",
    "    pass\n",
    "    reconstruct_X = None\n",
    "    switcher = {\n",
    "        0: reconstruct_pca,\n",
    "        1: reconstruct_kpca\n",
    "#         2: reconstruct_lda,\n",
    "#         3: reconstruct_klda,\n",
    "    }\n",
    "    func = switcher.get(choice)\n",
    "    reconstruct_X = func(*args)\n",
    "    return reconstruct_X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display results \n",
    "# Original \n",
    "counter = 0\n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    #feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    ind = np.random.randint(0,y_input.shape[0],6)\n",
    "    print('Original Images:')\n",
    "    X_orig = X_input.reshape((X_input.shape[0],32, 32, 3))\n",
    "    disply_images(X_orig[ind,...],y_input[ind], row=2, col=3)\n",
    "    \n",
    "    X_reconstructedPCA = reconstruct_images(0, X_input, no_eigenvals[counter], data)\n",
    "    #print(no_eigenvals[counter], X_reconstructedPCA.shape)\n",
    "    X_reconstructedKPCA = reconstruct_images(1, X_input, no_eigenvals[counter], 'rbf', 3)\n",
    "    # Show the reconstruction error\n",
    "    print('Reconstruction errors for: '+data)\n",
    "    print('PCA reconstruction error:', np.sqrt(np.mean((X_input - X_reconstructedPCA)**2)), end=',')\n",
    "    print(' KPCA reconstruction error:', np.sqrt(np.mean((X_input - X_reconstructedKPCA)**2)))\n",
    "    # Display random images\n",
    "    print('Reconstructed images using PCA:')\n",
    "    X_reconstructed = X_reconstructedPCA.reshape((X_reconstructedPCA.shape[0], 32, 32, 3))\n",
    "    disply_images(X_reconstructed[ind,...],y_input[ind], row=2, col=3)\n",
    "\n",
    "    print('Reconstructed images using KPCA:')\n",
    "    X_reconstructed = X_reconstructedKPCA.reshape((X_reconstructedKPCA.shape[0], 32, 32, 3))\n",
    "    disply_images(X_reconstructed[ind,...],y_input[ind], row=2, col=3)\n",
    "    counter = counter + 1\n",
    "\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(d). Which person/identity is difficult to represent com-pactly with fewer eigen vectors?  Why is that?  Explain with your empirical observations and intuitive answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here\n",
    "counter = 0\n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    #feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    class_number = len(np.unique(y_input))\n",
    "    pca_error = []\n",
    "    kpca_error = []\n",
    "    X_reconstructedPCA = reconstruct_images(0, X_input, no_eigenvals[counter], data)\n",
    "    X_reconstructedKPCA = reconstruct_images(1, X_input, no_eigenvals[counter], 'rbf', 3)\n",
    "    for i in range(class_number):\n",
    "        ith_class = X_input[np.where(y_input==i)]\n",
    "        ith_class_PCA =  X_reconstructedPCA[y_input==i]\n",
    "        ith_class_KPCA = X_reconstructedKPCA[y_input==i]\n",
    "        e1 = np.sqrt(np.mean((ith_class - ith_class_PCA)**2))\n",
    "        e2 = np.sqrt(np.mean((ith_class - ith_class_KPCA)**2))\n",
    "        pca_error.append((e1, i))\n",
    "        kpca_error.append((e2, i))\n",
    "    \n",
    "    print('For dataset '+data+':')\n",
    "    #print(pca_error)\n",
    "    max_pca = max(pca_error)[0]\n",
    "    max_kpca = max(kpca_error)[0]\n",
    "    print(max(pca_error)[1])\n",
    "    for i in range(class_number):\n",
    "        if 0.97*max_pca<=pca_error[i][0]:\n",
    "            print('Class', pca_error[i][1], 'has high pca reconstruction loss')\n",
    "        \n",
    "#         if 0.85*max_kpca>=kpca_error[i][0]:\n",
    "#             print('Class', kpca_error[i][1], 'has high kpca reconstruction loss')\n",
    "    counter = counter + 1\n",
    "\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2(a). Use any classifier(MLP, Logistic regression, SVM, Decision Trees) and find the classification accuracy. \n",
    "\n",
    "2(b)Which method works well? Do a comparitivestudy. \n",
    "\n",
    "\n",
    "You already know the paper [Face Recognition Us-ing  Kernel  Methods](!http://face-rec.org/algorithms/Kernel/nips01.pdf) .See  this  as  an  example for empirical analysis of different features/classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your classifier here. You can use libraries like sklearn to create your classifier \n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self, X, y, classifier_type):\n",
    "        #super.__init__()\n",
    "        self.classifier_type = classifier_type\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        if classifier_type == 'svm':\n",
    "            self.clf = SVC(gamma='auto', kernel='rbf', C = 1.0)\n",
    "        elif classifier_type == 'logistic':\n",
    "            self.clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=300, multi_class='multinomial')\n",
    "        elif classifier_type == 'mlp':\n",
    "            self.clf = MLPClassifier(hidden_layer_sizes=(200, 200), solver='adam', alpha=1e-5, random_state=1, learning_rate='adaptive', max_iter=500)\n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def classify(self,X):\n",
    "        \"\"\"\n",
    "            Given an input X classify it into appropriate class. \n",
    "        \"\"\"\n",
    "        prediction = self.clf.predict(X)\n",
    "        return prediction\n",
    "        \n",
    "    def confusion_mat(self,pred,y):\n",
    "        \"\"\"\n",
    "            A confusion matrix is a table that is often used to describe the performance of a classification\n",
    "            model (or “classifier”) on a set of test data for which the true values are known.\n",
    "            \n",
    "            \n",
    "            @return confusion_matrix => num_classesxnum_classes martix \n",
    "                where confusion_matrix[i,j] = number of prediction which are i and number of ground truth value equal j \n",
    "        \n",
    "        \"\"\"\n",
    "        return confusion_matrix(pred, y)\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.clf.fit(X_train, y_train)\n",
    "        \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is the classifier on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters and judge the classification\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier validated. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        y_predicted = self.classify(X_validate)\n",
    "        # Create a confusion matrix\n",
    "        self.conf_matrix = self.confusion_mat(y_predicted, y_validate)\n",
    "        #print(confusion_mat)\n",
    "        \n",
    "        # Calculate Validation accuracy \n",
    "        count = np.count_nonzero(y_predicted == y_validate)\n",
    "        self.accuracy = ((count/y_test.shape[0])*100)\n",
    "        \n",
    "        metrics = precision_recall_fscore_support(y_validate, y_predicted, beta=1.0, average='macro')\n",
    "        \n",
    "        # Calculate precision and recall \n",
    "        self.precision = metrics[0]\n",
    "        self.recall = metrics[1]\n",
    "        \n",
    "        # Calculate F1-score\n",
    "        self.f1score = metrics[2]\n",
    "#         return metrics[2], accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train and validation split to train your classifier \n",
    "feature_space = {'0': 'PCA', \n",
    "                 '1': 'KPCA',\n",
    "                 '2': 'LDA', \n",
    "                 '3': 'KLDA', \n",
    "                 '4': 'VGG',\n",
    "                 '5': 'RESNET',\n",
    "                 '6': 'RESNET+VGG',\n",
    "                 '7': 'KPCA+KLDA', \n",
    "                 '8': 'ALL FEATURES'\n",
    "                }\n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    reduced_space = []\n",
    "    feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    print('Results for '+data+':')\n",
    "    for index in feature_input.keys():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feature_input[index], y_input, test_size=0.2, random_state=76)\n",
    "        print(\"Feature Space:\", feature_space[index])\n",
    "        index = int(index)\n",
    "\n",
    "        svm_classifier = Classifier(X, y, 'svm')\n",
    "        svm_classifier.train(X_train, y_train)\n",
    "        svm_classifier.validate(X_test, y_test)\n",
    "        print(\"svm classifier: \", f'{svm_classifier.accuracy:.2f}', ', ', end=\"\")\n",
    "\n",
    "        logistic_classifier = Classifier(X, y, 'logistic')\n",
    "        logistic_classifier.train(X_train, y_train)\n",
    "        logistic_classifier.validate(X_test, y_test)\n",
    "        print(\"logistic classifier: \", f'{logistic_classifier.accuracy:.2f}', ', ', end=\"\")\n",
    "\n",
    "        mlp_classifier = Classifier(X, y, 'mlp')\n",
    "        mlp_classifier.train(X_train, y_train)\n",
    "        mlp_classifier.validate(X_test, y_test)\n",
    "        print(\"mlp classifier: \", f'{mlp_classifier.accuracy:.2f}')\n",
    "        print()\n",
    "\n",
    "# print 3 classification accuaracies for each of the feature spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = {}\n",
    "for data in datasets:\n",
    "    df_list[data] =  pd.DataFrame(columns=['Method', 'Reduced Space', 'Error', 'Accuracy', 'F1-score'], index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, classification error, accuracy, f1-score\n",
    "# Print the table. (You can use Pandas)\\\n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    reduced_space = []\n",
    "    feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    for index in indices:\n",
    "        reduced_space.append(feature_input[index].shape[1])\n",
    "    #print(data)\n",
    "    #print(reduced_space)\n",
    "    for key in feature_input.keys():\n",
    "        mlp_classifier = Classifier(X_input, y_input, 'mlp')\n",
    "        #print(feature_input[key].shape[0], y_input.shape)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feature_input[key], y_input, test_size=0.2, random_state=76)\n",
    "        mlp_classifier.train(X_train, y_train)\n",
    "        mlp_classifier.validate(X_test, y_test)\n",
    "        #print(a, b)\n",
    "        index = int(key)\n",
    "        #print(type(key))\n",
    "        #print(mlp_classifier.accuracy, mlp_classifier.f1score)\n",
    "        df_list[data].loc[key] = [ method[index], feature_input[key].shape[1], 100 - mlp_classifier.accuracy, mlp_classifier.accuracy, float(mlp_classifier.f1score)]\n",
    "    \n",
    "    print(data+' Dataset:')\n",
    "    display(df_list[data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset print the confusion matrix for the best model \n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    #reduced_space = []\n",
    "    feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    df = df_list[data]\n",
    "    df['F1-score'] = pd.to_numeric(df['F1-score'])\n",
    "    max_f1score_index = df['F1-score'].idxmax()\n",
    "    #method = df.loc[max_f1score_index]['Method']\n",
    "    #print(method)\n",
    "    mlp_classifier = Classifier(X_input, y_input, 'mlp')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_input[max_f1score_index], y_input, test_size=0.2, random_state=76)\n",
    "    mlp_classifier.train(X_train, y_train)\n",
    "    mlp_classifier.validate(X_test, y_test)\n",
    "    print(data+' Dataset:')\n",
    "    print(mlp_classifier.conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Similiar to 1(b) use t-SNE based visilization of faces?  Does it makesense?  Do you see similar people coming together?or something else?  Can you do visualization datasetwise and combined? Here you will use a popular implementation.(Worth  reading and understanding  t-SNE.  We  will not discuss it in the class and out of scope for thiscourse/exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TSNE for different features and create a scatter plot\n",
    "\n",
    "#X =  # feature \n",
    "k = 3 # Number of components in TSNE\n",
    "\n",
    "# Compute\n",
    "for data in datasets:\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    for index in feature_input.keys():\n",
    "        if index == '2' or index == '3':\n",
    "            X_TSNE = TSNE(n_components=k, perplexity=8, learning_rate=10, n_iter=5000, random_state=123).fit_transform(feature_input[index])\n",
    "            # Plot the representation in 2d/3d\n",
    "            fig = plt.figure(figsize=(12,12))\n",
    "            # ax = fig.add_subplot(111, projection='3d')\n",
    "            ax = plt.subplot(aspect='equal')\n",
    "            no_class = len(np.unique(y_input))\n",
    "            palette = np.array(sns.color_palette(\"bright\", no_class))\n",
    "            ax.scatter(X_TSNE[:,0], X_TSNE[:,1], c=palette[y_input.astype(np.int)])\n",
    "            fig.savefig('a2plots/TSNE/'+method[int(index)]+'_TSNE_'+data+'.png')\n",
    "            #plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.`face`  is  used  for  verification.   \n",
    "\n",
    "4(a) How do we formulate the problem using KNN \n",
    "\n",
    "4(b) How do we analyze the performance ? suggest  the  metrics  (like  accuracy) that is appropriate for this task.\n",
    "\n",
    "_______________________________________________________________________\n",
    "\n",
    "4(c)Show empirical re-sults  with  all  the  representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceVerification():\n",
    "    def __init__(self, no_neigh):\n",
    "        #super.__init__()\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=no_neigh)\n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def classify(self,X,y_validate):\n",
    "        \"\"\"\n",
    "            Given an input X find if the class id is correct or not.\n",
    "            \n",
    "            @return verfication_results => N vector containing True or False. \n",
    "                    If the class-id matches with your prediction then true else false.   \n",
    "        \"\"\"\n",
    "        predicted = self.knn.predict(X)\n",
    "        results = np.ones(predicted.shape[0], dtype=bool)\n",
    "        for i in range(predicted.shape[0]):\n",
    "            if y_validate[i]!=predicted[i]:\n",
    "                results[i] = False\n",
    "        return results\n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your verification system will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.knn.fit(X_train, y_train)\n",
    "        \n",
    "    def verify(self, X, class_id):\n",
    "        X = X.reshape((1, X.shape[0]))\n",
    "        predcited_class = self.knn.predict(X)\n",
    "        if predcited_class == class_id:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is your system on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        predicted = self.knn.predict(X_validate)\n",
    "        results = self.classify(X_validate, y_validate)\n",
    "        metrics = precision_recall_fscore_support(y_validate, predicted, beta=1.0, average='macro')\n",
    "        #print(results)\n",
    "        self.accuracy = (np.count_nonzero(results==True)/results.shape[0])*100\n",
    "        #print(self.accuracy)\n",
    "        self.precision = metrics[0]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a train and validation split and show your results\n",
    "for data in datasets:\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ax.set_xlim([0,15])\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    for index in feature_input.keys():\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feature_input[index], y_input, test_size=0.2, random_state=76)\n",
    "        knn_accuracies = []\n",
    "        for no_neigh in range(3, 15):\n",
    "            knn_classifier = FaceVerification(no_neigh)\n",
    "            knn_classifier.train(X_train, y_train)\n",
    "            results = knn_classifier.validate(X_test, y_test)\n",
    "            #knn_acc = np.count_nonzero(results==True)\n",
    "            #Accuray for knn\n",
    "            knn_accuracies.append(knn_classifier.accuracy)\n",
    "            #print('Accuracy for ' + method[int(index)] + '+KNN: ', (knn_acc/results.shape[0])*100)\n",
    "        #print(knn_accuracies)\n",
    "        plt.plot(range(3, 15), knn_accuracies, label=method[int(index)])\n",
    "        if index=='5':\n",
    "            break\n",
    "    plt.xlabel('no of nearest neighbours')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=3, fancybox=True, shadow=True)\n",
    "    plt.ylabel('Percentage Accuracy')\n",
    "    plt.title(data)\n",
    "    plt.savefig('a2plots/KNN/'+'knn_'+data+'.png')\n",
    "    plt.show()\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list1 = {}\n",
    "for data in datasets:\n",
    "    df_list1[data] =  pd.DataFrame(columns=['Method', 'Reduced Space', 'Verification Error', 'Accuracy', 'Precision'], index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emperical results for KLDA feature space\n",
    "knn_classifier = FaceVerification(3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features['2'], y, test_size=0.2, random_state=76)\n",
    "knn_classifier.train(X_train, y_train)\n",
    "ind = np.random.randint(0,y.shape[0],6)\n",
    "for index in ind:\n",
    "    #print(features['2'][index])\n",
    "    response = knn_classifier.verify(features['2'][index], y[index])\n",
    "    if response:\n",
    "        print('Yes')\n",
    "    else:\n",
    "        print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, verification error, accuracy, precision\n",
    "for data in datasets:\n",
    "    #data = 'IMFDB'\n",
    "    X_input, y_input = load_dataset('./dataset/'+data)\n",
    "    reduced_space = []\n",
    "    feature_input = return_features(X_input, y_input, './dataset/'+data, 100)\n",
    "    \n",
    "    for index in indices:\n",
    "        reduced_space.append(feature_input[index].shape[1])\n",
    "        \n",
    "    for key in feature_input.keys():\n",
    "        knn = FaceVerification(3)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feature_input[key], y_input, test_size=0.2, random_state=76)\n",
    "        knn.train(X_train, y_train)\n",
    "        knn.validate(X_test, y_test)\n",
    "        index = int(key)\n",
    "        df_list1[data].loc[key] = [ method[index], feature_input[key].shape[1], 100 - knn.accuracy, knn.accuracy, float(knn.precision)]\n",
    "    \n",
    "    print(data+' Dataset:')\n",
    "    display(df_list1[data])\n",
    "# Print the table. (You can use Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extenstion / Application\n",
    "    Create a system for any one of the following problems:\n",
    "\n",
    "- Politicians  vs  Filmstars  in  a  public  data  set.   (eg.LFW)\n",
    "        You already have seen IIIT-CFW dataset. Use it for classification. \n",
    "- Age prediction\n",
    "        Given different actors/actress in IMFDB create new labels based on their age.  \n",
    "- Gender prediction\n",
    "        Given different actors/actress in IMFDB+IIIT-CFW create new labels based on their gender.\n",
    "- Emotion classification\n",
    "        Both the yale dataset and IMFDB contain an `emotion.txt` file. Using that you can create a emotion predicter \n",
    "- cartoon vs real images\n",
    "        Use a combination of IIIT-CFW and other dataset. \n",
    "        \n",
    "\n",
    "\n",
    "You are free to use a new dataset that is publicly avail-able or even create one by crawling from internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# def load_emodata(dir_path):\n",
    "#     image_list = []\n",
    "#     y_list = []\n",
    "    \n",
    "#     if \"CFW\" in dir_path:\n",
    "#         label_dict = cfw_dict\n",
    "\n",
    "#     elif \"yale\" in dir_path.lower():\n",
    "#         label_dict = {}\n",
    "#         for i in range(11):\n",
    "#             label_dict[str(i)] = i\n",
    "#     elif \"IMFDB\" in dir_path:\n",
    "#         label_dict = imfdb_dict\n",
    "#     else:\n",
    "#         raise KeyError(\"Dataset not found.\")\n",
    "    \n",
    "    \n",
    "#     for filename in sorted(os.listdir(dir_path)):\n",
    "#         if filename.endswith(\".png\"):\n",
    "#             im = load_image(os.path.join(dir_path,filename))\n",
    "#             y = filename.split('_')[1].split('.')[0]\n",
    "#             y = label_dict[y] \n",
    "#             #print(filename, y)\n",
    "#             image_list.append(im)\n",
    "#             y_list.append(y)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#     image_list = np.array(image_list)\n",
    "#     y_list = np.array(y_list)\n",
    "\n",
    "#     print(\"Dataset shape:\", image_list.shape)\n",
    "\n",
    "#     return image_list,y_list\n",
    "def get_data_with_emotions(dir_path):\n",
    "    image_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    if \"yale\" in dir_path.lower():\n",
    "        emotions = pd.read_csv('./dataset/Yale_face_database/emotiom.txt',header=None)\n",
    "    elif \"IMFDB\" in dir_path:\n",
    "        emotions = pd.read_csv('./dataset/IMFDB/emotion.txt',header=None)\n",
    "    else:\n",
    "        raise KeyError(\"Dataset not found.\")\n",
    "    \n",
    "    \n",
    "    for filename in sorted(os.listdir(dir_path)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            im = load_image(os.path.join(dir_path,filename))\n",
    "            y = emotions.loc[emotions[0] == filename].iloc[0,1]\n",
    "            image_list.append(im)\n",
    "            y_list.append(y)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    y_list = np.array(y_list)\n",
    "\n",
    "    print(\"Dataset shape:\",image_list.shape)\n",
    "\n",
    "    return image_list,y_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(dirpath):\n",
    "    X_final,emotions = get_data_with_emotions(dirpath)\n",
    "    N,H,W = X_final.shape[0:3]\n",
    "    C = 1 if opt['is_grayscale'] else X_final.shape[3]\n",
    "    X_final = np.reshape(X_final,(N,(H*W*C)))\n",
    "    em_unique = list(set(emotions))\n",
    "    y_final = np.array([em_unique.index(em) for em in emotions])\n",
    "    return X_final, y_final, emotions, em_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = './dataset/Yale_face_database/'\n",
    "dirpath1 = './dataset/IMFDB/'\n",
    "X_final, y_final, emotions, em_unique = get_input('./dataset/Yale_face_database/')\n",
    "X_final1, y_final1, emotions1, em_unique1 = get_input('./dataset/IMFDB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your features\n",
    "\n",
    "features_emo = return_features(X_final, y_final, dirpath, 100)\n",
    "features_emo1 = return_features(X_final1, y_final1, dirpath1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_mod(MLPClassifier):\n",
    "    def _init_coef(self, fan_in, fan_out):\n",
    "        init_bound = np.sqrt(2. / (fan_in + fan_out))\n",
    "        coef_init = self._random_state.uniform(-init_bound, init_bound,\n",
    "                                               (fan_in, fan_out))\n",
    "        coef_init = np.random.normal(0,1,(fan_in, fan_out)) / np.sqrt(fan_in+fan_out)\n",
    "        intercept_init = self._random_state.uniform(-init_bound, init_bound,\n",
    "                                                    fan_out)\n",
    "        intercept_init = np.random.normal(0,1,fan_out)/np.sqrt(fan_out)\n",
    "        return coef_init, intercept_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_classifier(features_emo, y_final):\n",
    "    classifier = mlp_mod(alpha= 1e-3,learning_rate= 'adaptive',solver='adam',epsilon = 1, beta_1 = 0.2,beta_2 =0.2, hidden_layer_sizes=(100, 200, 100),max_iter = 5000, verbose=False, tol=1e-5, activation='relu')\n",
    "    # Validate your classifier\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_emo['2'],y_final,test_size = 0.2, random_state = 76)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    predicter = classifier.predict(X_test)\n",
    "    counting = np.count_nonzero(y_test == predicter)\n",
    "    class_acc = ((counting/y_test.shape[0])*100)\n",
    "    print('Testing accuracy: ', class_acc)\n",
    "\n",
    "    predicter = classifier.predict(X_train)\n",
    "    counting = np.count_nonzero(y_train == predicter)\n",
    "    class_acc = ((counting/y_train.shape[0])*100)\n",
    "    print('Training accuracy: ', class_acc)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier = return_classifier(features_emo, y_final)\n",
    "classifier1 = return_classifier(features_emo1, y_final1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross_valid_acc = np.mean(cross_val_score(classifier, features_emo['2'], y_final, cv=5))*100\n",
    "print('Cross K-Fold Accuracy with k =5: for Yale dataset', Cross_valid_acc)\n",
    "Cross_valid_acc1 = np.mean(cross_val_score(classifier1, features_emo1['2'], y_final1, cv=5))*100\n",
    "print('Cross K-Fold Accuracy with k =5: for IMFDB dataset', Cross_valid_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_SNE(features_emo, y_final, dirpath):\n",
    "    X_TSNE = TSNE(n_components=2).fit_transform(features_emo['2'])\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    # ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    no_class = len(np.unique(y_final))\n",
    "    palette = np.array(sns.color_palette(\"hls\", no_class))\n",
    "    # print(no_class)\n",
    "    ax.set_title('t-SNE')\n",
    "    ax.scatter(X_TSNE[:,0], X_TSNE[:,1], c=palette[y_final.astype(np.int)])\n",
    "    fig.savefig(dirpath+'TSNE.png')\n",
    "    #plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(features_emo, y_final, dirpath):\n",
    "    X_PCA = get_pca(features_emo['2'],2)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    ax.scatter(X_PCA[:,0],X_PCA[:,1],c=palette[y_final.astype(np.int)])\n",
    "    ax.set_title('PCA')\n",
    "    fig.savefig(dirpath+'PCA.png')\n",
    "    #plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isomap(features_emo, y_final, dirpath):\n",
    "    embedding = Isomap(n_components=2, n_neighbors=4)\n",
    "    X_trans = embedding.fit_transform(features_emo['2'])\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    ax.scatter(X_trans[:,0],X_trans[:,1],c=palette[y_final.astype(np.int)])\n",
    "    ax.set_title('Isompap')\n",
    "    fig.savefig(dirpath+'Isomap.png')\n",
    "    #plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show qualitative results such as accuracy, k-fold validation, TSNE/PCA/Isomap plots, etc.  \n",
    "# tf\n",
    "\n",
    "#TSNE plot\n",
    "t_SNE(features_emo, y_final, './q21_plots')\n",
    "t_SNE(features_emo1, y_final1, './q22_plots')\n",
    "#PCA plot\n",
    "pca(features_emo, y_final, './q21_plots')\n",
    "pca(features_emo1, y_final1, './q22_plots')\n",
    "#Isomaps plot\n",
    "isomap(features_emo, y_final, './q21_plots')\n",
    "isomap(features_emo1, y_final1, './q22_plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantitative results such as examples of correct prediction and wrong prediction\n",
    "ind = np.random.randint(0,y_final.shape[0],6)\n",
    "print(ind)\n",
    "# Original images\n",
    "pred_labels = classifier.predict(features_emo['2'][ind])\n",
    "truth_labels = y_final[ind]\n",
    "#print(em_unique)\n",
    "print(pred_labels, truth_labels)\n",
    "for j in range(6):\n",
    "    if pred_labels[j]!=truth_labels[j]:\n",
    "        print('Wrong Prediction:', em_unique[pred_labels[j]], ',Correct Answer:', em_unique[truth_labels[j]])\n",
    "    else:\n",
    "        print('Correct Prediction:', em_unique[truth_labels[j]])\n",
    "\n",
    "X_4dim = X_final.reshape((X_final.shape[0], 32, 32, 3))\n",
    "disply_images(X_4dim[ind,...],y_final[ind], row=2, col=3)\n",
    "print(em_unique[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantitative results such as examples of correct prediction and wrong prediction\n",
    "ind = np.random.randint(0,y_final1.shape[0],6)\n",
    "print(ind)\n",
    "# Original images\n",
    "pred_labels = classifier1.predict(features_emo1['2'][ind])\n",
    "truth_labels = y_final1[ind]\n",
    "print(em_unique1)\n",
    "print(pred_labels, truth_labels)\n",
    "for j in range(6):\n",
    "    if pred_labels[j]!=truth_labels[j]:\n",
    "        print('Wrong Prediction:', em_unique1[pred_labels[j]], ',Correct Answer:', em_unique1[truth_labels[j]])\n",
    "    else:\n",
    "        print('Correct Prediction:', em_unique1[truth_labels[j]])\n",
    "\n",
    "X_4dim = X_final1.reshape((X_final1.shape[0], 32, 32, 3))\n",
    "disply_images(X_4dim[ind,...],y_final1[ind], row=2, col=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
